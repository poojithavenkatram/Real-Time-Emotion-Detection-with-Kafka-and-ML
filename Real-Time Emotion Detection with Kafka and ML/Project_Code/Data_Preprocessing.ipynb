{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> Real-Time Emotion Detection with Kafka, Spark Streaming, and Machine Learning </h1>\n",
    "    <h2> Data Preprocessing </h2>\n",
    "    <h4> Ann Maria John, Divya Neelamegam, Kartik Mukkavilli, Poojitha Venkat Ram, Shruti Badrinarayanan </h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load already Split Data (CSV files) into separate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text  label\n",
       " 0                            i didnt feel humiliated      0\n",
       " 1  i can go from feeling so hopeless to so damned...      0\n",
       " 2   im grabbing a minute to post i feel greedy wrong      3\n",
       " 3  i am ever feeling nostalgic about the fireplac...      2\n",
       " 4                               i am feeling grouchy      3,\n",
       "                                                 text  label\n",
       " 0  im feeling quite sad and sorry for myself but ...      0\n",
       " 1  i feel like i am still looking at a blank canv...      0\n",
       " 2                     i feel like a faithful servant      2\n",
       " 3                  i am just feeling cranky and blue      3\n",
       " 4  i can have for a treat or if i am feeling festive      1,\n",
       "                                                 text  label\n",
       " 0  im feeling rather rotten so im not very ambiti...      0\n",
       " 1          im updating my blog because i feel shitty      0\n",
       " 2  i never make her separate from me because i do...      0\n",
       " 3  i left with my bouquet of red and yellow tulip...      1\n",
       " 4    i was feeling a little vain when i did this one      0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "training_data_path = 'Raw Data/training.csv'\n",
    "validation_data_path = 'Raw Data/validation.csv'\n",
    "test_data_path = 'Raw Data/test.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "validation_data = pd.read_csv(validation_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Display the first few rows of each dataset to understand the structure\n",
    "(training_data.head(), validation_data.head(), test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                i didnt feel humiliated      0\n",
       "1      i can go from feeling so hopeless to so damned...      0\n",
       "2       im grabbing a minute to post i feel greedy wrong      3\n",
       "3      i am ever feeling nostalgic about the fireplac...      2\n",
       "4                                   i am feeling grouchy      3\n",
       "...                                                  ...    ...\n",
       "15995  i just had a very brief time in the beanbag an...      0\n",
       "15996  i am now turning and i feel pathetic that i am...      0\n",
       "15997                     i feel strong and good overall      1\n",
       "15998  i feel like this was such a rude comment and i...      3\n",
       "15999  i know a lot but i feel so stupid because i ca...      0\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     im feeling quite sad and sorry for myself but ...      0\n",
       "1     i feel like i am still looking at a blank canv...      0\n",
       "2                        i feel like a faithful servant      2\n",
       "3                     i am just feeling cranky and blue      3\n",
       "4     i can have for a treat or if i am feeling festive      1\n",
       "...                                                 ...    ...\n",
       "1995  im having ssa examination tomorrow in the morn...      0\n",
       "1996  i constantly worry about their fight against n...      1\n",
       "1997  i feel its important to share this info for th...      1\n",
       "1998  i truly feel that if you are passionate enough...      1\n",
       "1999  i feel like i just wanna buy any cute make up ...      1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     im feeling rather rotten so im not very ambiti...      0\n",
       "1             im updating my blog because i feel shitty      0\n",
       "2     i never make her separate from me because i do...      0\n",
       "3     i left with my bouquet of red and yellow tulip...      1\n",
       "4       i was feeling a little vain when i did this one      0\n",
       "...                                                 ...    ...\n",
       "1995  i just keep feeling like someone is being unki...      3\n",
       "1996  im feeling a little cranky negative after this...      3\n",
       "1997  i feel that i am useful to my people and that ...      1\n",
       "1998  im feeling more comfortable with derby i feel ...      1\n",
       "1999  i feel all weird when i have to meet w people ...      4\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = training_data.drop_duplicates()\n",
    "validation_data = validation_data.drop_duplicates()\n",
    "test_data = test_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This notebook is a complete pipeline for preprocessing text data for natural language processing (NLP) tasks for the emotion recognition/detection project. It begins by downloading necessary resources from NLTK, like WordNet for lemmatization and the Punk tokenizer. The preprocess_text function is defined to convert text to lowercase, tokenize it, perform lemmatization, handle negations (e.g., transforming \"not happy\" into \"not_happy\"), and remove punctuation, numbers, and English stop words. This function is then applied to text data from training, validation, and test datasets loaded from CSV files. Next, a TF-IDF Vectorizer is initialized to consider uni-grams, bi-grams, and tri-grams, while ignoring rare words appearing in fewer than two documents. This vectorizer is then fitted on the training data and used to transform all datasets. Finally, the transformed TF-IDF data is saved in a sparse matrix format (npz files) in a directory named 'Preprocessed Data', and the file paths for the saved data are returned for confirmation. This pipeline effectively prepares text data for the machine learning modeling stage, optimizing it for analysis and pattern recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Preprocessed Data/training_tfidf.npz',\n",
       " 'Preprocessed Data/validation_tfidf.npz',\n",
       " 'Preprocessed Data/test_tfidf.npz')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "import scipy.sparse as sp\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define the preprocessing function including stop words removal\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lemmatization and handling negations\n",
    "    prev_word = \"\"\n",
    "    processed_tokens = []\n",
    "    for word in tokens:\n",
    "        if word in ENGLISH_STOP_WORDS:\n",
    "            continue\n",
    "        if word == \"not\":\n",
    "            prev_word = \"not_\"\n",
    "        else:\n",
    "            if prev_word == \"not_\":\n",
    "                word = prev_word + word\n",
    "                prev_word = \"\"\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            # Remove punctuation and numbers\n",
    "            word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            word = re.sub(r'\\d+', '', word)\n",
    "            processed_tokens.append(word)\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Load the datasets again\n",
    "training_data = pd.read_csv('Raw Data/training.csv')\n",
    "validation_data = pd.read_csv('Raw Data/validation.csv')\n",
    "test_data = pd.read_csv('Raw Data/test.csv')\n",
    "\n",
    "# Apply the preprocessing to the text data\n",
    "training_data['text'] = training_data['text'].apply(preprocess_text)\n",
    "validation_data['text'] = validation_data['text'].apply(preprocess_text)\n",
    "test_data['text'] = test_data['text'].apply(preprocess_text)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer without max_features to keep all words\n",
    "# Configure the TF-IDF vectorizer to include bi-grams and tri-grams and to ignore rare words that appear in less than two documents.\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), min_df=2)\n",
    "\n",
    "# Fit the vectorizer on the training text data and transform all datasets\n",
    "tfidf_vectorizer.fit(training_data['text'])\n",
    "training_data_tfidf = tfidf_vectorizer.transform(training_data['text'])\n",
    "validation_data_tfidf = tfidf_vectorizer.transform(validation_data['text'])\n",
    "test_data_tfidf = tfidf_vectorizer.transform(test_data['text'])\n",
    "\n",
    "# Save the TF-IDF data as .npz files since they are in sparse format\n",
    "preprocessed_data_dir = 'Preprocessed Data/'\n",
    "os.makedirs(preprocessed_data_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths for the TF-IDF data\n",
    "training_data_tfidf_file = os.path.join(preprocessed_data_dir, 'training_tfidf.npz')\n",
    "validation_data_tfidf_file = os.path.join(preprocessed_data_dir, 'validation_tfidf.npz')\n",
    "test_data_tfidf_file = os.path.join(preprocessed_data_dir, 'test_tfidf.npz')\n",
    "\n",
    "# Save the TF-IDF data\n",
    "sp.save_npz(training_data_tfidf_file, training_data_tfidf)\n",
    "sp.save_npz(validation_data_tfidf_file, validation_data_tfidf)\n",
    "sp.save_npz(test_data_tfidf_file, test_data_tfidf)\n",
    "\n",
    "# Return the file paths for confirmation\n",
    "(training_data_tfidf_file, validation_data_tfidf_file, test_data_tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aa meeting', 'abandon', ..., 'zoom', 'zooming', 'zumba'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Modeling using Multinomial Naive Bayes on Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       550\n",
      "           1       0.69      0.98      0.81       704\n",
      "           2       1.00      0.14      0.25       178\n",
      "           3       0.96      0.48      0.64       275\n",
      "           4       0.90      0.49      0.63       212\n",
      "           5       1.00      0.09      0.16        81\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.88      0.52      0.55      2000\n",
      "weighted avg       0.80      0.74      0.69      2000\n",
      "\n",
      "Accuracy: 0.739\n",
      "\n",
      "Confusion Matrix:\n",
      "[[518  30   0   1   1   0]\n",
      " [ 11 693   0   0   0   0]\n",
      " [ 35 118  25   0   0   0]\n",
      " [ 69  72   0 132   2   0]\n",
      " [ 55  50   0   4 103   0]\n",
      " [ 28  37   0   0   9   7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# File paths\n",
    "training_data_tfidf_file = 'Preprocessed Data/training_tfidf.npz'\n",
    "validation_data_tfidf_file = 'Preprocessed Data/validation_tfidf.npz'\n",
    "test_data_tfidf_file = 'Preprocessed Data/test_tfidf.npz'\n",
    "\n",
    "# Load the data\n",
    "training_data_tfidf = sp.load_npz(training_data_tfidf_file)\n",
    "validation_data_tfidf = sp.load_npz(validation_data_tfidf_file)\n",
    "test_data_tfidf = sp.load_npz(test_data_tfidf_file)\n",
    "\n",
    "# Load the labels (assuming they are stored in the DataFrame)\n",
    "training_labels = training_data['label']\n",
    "validation_labels = validation_data['label']\n",
    "test_labels = test_data['label']\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(training_data_tfidf, training_labels)\n",
    "\n",
    "# Predict on validation and test data\n",
    "validation_predictions = nb_classifier.predict(validation_data_tfidf)\n",
    "test_predictions = nb_classifier.predict(test_data_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(validation_labels, validation_predictions))\n",
    "print(\"Accuracy:\", accuracy_score(validation_labels, validation_predictions))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(validation_labels, validation_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_classifier.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# After training the classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(training_data_tfidf, training_labels)\n",
    "\n",
    "# Save the model to a joblib file\n",
    "model_filename = 'naive_bayes_classifier.joblib'\n",
    "dump(nb_classifier, model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
